doc_id,document,top_k,category,input_data,answer
02567fd428a675ca91a0c6786f47f3e35881bcbd,"document : Deep Label Distribution Learning With Label Ambiguity Convolutional Neural Networks ( ConvNets ) have achieved excellent recognition performance in various visual recognition tasks . A large labeled training set is one of the most important factors for its success . However , it is difficult to collect sufficient training images with precise labels in some domains such as apparent age estimation , head pose estimation , multi - label classification and semantic segmentation . Fortunately , there is ambiguous information among labels , which makes these tasks different from traditional classification .",5,"['Task', 'Method', 'Material', 'Metric']","document : Deep Label Distribution Learning With Label Ambiguity Convolutional Neural Networks ( ConvNets ) have achieved excellent recognition performance in various visual recognition tasks . A large labeled training set is one of the most important factors for its success . However , it is difficult to collect sufficient training images with precise labels in some domains such as apparent age estimation , head pose estimation , multi - label classification and semantic segmentation . Fortunately , there is ambiguous information among labels , which makes these tasks different from traditional classification .","{'Task': ['semantic segmentation', 'age estimation', 'head pose estimation', 'Label Ambiguity', 'classification', 'multi - label classification', 'recognition', 'visual recognition tasks'], 'Method': ['Deep Label Distribution Learning', 'Convolutional Neural Networks', 'ConvNets'], 'Material': [], 'Metric': []}"
02b3d1d162080d9aefd3fc30a0bcc9a843073b5d,"In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling , a task central to language understanding . We extend current models to deal with two key challenges present in this task : corpora and vocabulary sizes , and complex , long term structure of language . We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long - Short Term Memory , on the One Billion Word Benchmark . Our best single model significantly improves state - of - the - art perplexity from 51.3 down to 30.0 ( whilst reducing the number of parameters by a factor of 20 ) , while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7 . We also release these models for the NLP and ML community to study and improve upon .",5,"['Task', 'Method', 'Material', 'Metric']","In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling , a task central to language understanding . We extend current models to deal with two key challenges present in this task : corpora and vocabulary sizes , and complex , long term structure of language . We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long - Short Term Memory , on the One Billion Word Benchmark . Our best single model significantly improves state - of - the - art perplexity from 51.3 down to 30.0 ( whilst reducing the number of parameters by a factor of 20 ) , while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7 . We also release these models for the NLP and ML community to study and improve upon .","{'Task': ['language understanding', 'Language Modeling', 'NLP and ML community'], 'Method': ['character Convolutional Neural Networks', 'Recurrent Neural Networks', 'ensemble of models', 'Long - Short Term Memory'], 'Material': ['One Billion Word Benchmark'], 'Metric': ['perplexity']}"
0398552184f80db111e9c28bf533b395f233ac00,"Bridging Saliency Detection to Weakly Supervised Object Detection Based on Self - paced Curriculum Learning section : Abstract Weakly - supervised object detection ( WOD ) is a challenging problems in computer vision . The key problem is to simultaneously infer the exact object locations in the training images and train the object detectors , given only the training images with weak image - level labels . Intuitively , by simulating the selective attention mechanism of human visual system , saliency detection technique can select attractive objects in scenes and thus is a potential way to provide useful priors for WOD .",5,"['Task', 'Method', 'Material', 'Metric']","Bridging Saliency Detection to Weakly Supervised Object Detection Based on Self - paced Curriculum Learning section : Abstract Weakly - supervised object detection ( WOD ) is a challenging problems in computer vision . The key problem is to simultaneously infer the exact object locations in the training images and train the object detectors , given only the training images with weak image - level labels . Intuitively , by simulating the selective attention mechanism of human visual system , saliency detection technique can select attractive objects in scenes and thus is a potential way to provide useful priors for WOD .","{'Task': ['WOD', 'saliency detection', 'Weakly Supervised Object Detection', 'Bridging Saliency Detection', 'Weakly - supervised object detection', 'computer vision'], 'Method': ['object detectors', 'Self - paced Curriculum Learning', 'human visual system', 'selective attention mechanism'], 'Material': [], 'Metric': []}"
05d2700846c0323f79c1344aca5333994c7c03a5,"document : The IBM 2016 English Conversational Telephone Speech Recognition System We describe a collection of acoustic and language modeling techniques that lowered the word error rate of our English conversational telephone LVCSR system to a record 6.6 % on the Switchboard subset of the Hub5 2000 evaluation testset . On the acoustic side , we use a score fusion of three strong models : recurrent nets with maxout activations , very deep convolutional nets with 3x3 kernels , and bidirectional long short - term memory nets which operate on FMLLR and i - vector features . On the language modeling side , we use an updated model “ M ” and hierarchical neural network LMs . GeorgeSaon , TomSercu , StevenRennieandHong - KwangJ.Kuo IBMT.J.WatsonResearchCenter , YorktownHeights , NY , 10598 gsaon@us.ibm.com",5,"['Task', 'Method', 'Material', 'Metric']","document : The IBM 2016 English Conversational Telephone Speech Recognition System We describe a collection of acoustic and language modeling techniques that lowered the word error rate of our English conversational telephone LVCSR system to a record 6.6 % on the Switchboard subset of the Hub5 2000 evaluation testset . On the acoustic side , we use a score fusion of three strong models : recurrent nets with maxout activations , very deep convolutional nets with 3x3 kernels , and bidirectional long short - term memory nets which operate on FMLLR and i - vector features . On the language modeling side , we use an updated model “ M ” and hierarchical neural network LMs . GeorgeSaon , TomSercu , StevenRennieandHong - KwangJ.Kuo IBMT.J.WatsonResearchCenter , YorktownHeights , NY , 10598 gsaon@us.ibm.com","{'Task': ['language modeling side', 'IBM 2016 English Conversational Telephone Speech Recognition System'], 'Method': ['3x3 kernels', 'maxout activations', 'strong models', 'recurrent nets', 'bidirectional long short - term memory nets', 'deep convolutional nets', 'updated model', 'acoustic and language modeling techniques', 'English conversational telephone LVCSR system', 'M ”', 'hierarchical neural network LMs'], 'Material': ['Switchboard subset'], 'Metric': ['word error rate']}"
0626908dd710b91aece1a81f4ca0635f23fc47f3,"document : Rethinking the Inception Architecture for Computer Vision Convolutional networks are at the core of most state - of - the - art computer vision solutions for a wide variety of tasks . Since 2014 very deep convolutional networks started to become mainstream , yielding substantial gains in various benchmarks . Although increased model size and computational cost tend to translate to immediate quality gains for most tasks ( as long as enough labeled data is provided for training ) , computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big - data scenarios . Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization .",5,"['Task', 'Method', 'Material', 'Metric']","document : Rethinking the Inception Architecture for Computer Vision Convolutional networks are at the core of most state - of - the - art computer vision solutions for a wide variety of tasks . Since 2014 very deep convolutional networks started to become mainstream , yielding substantial gains in various benchmarks . Although increased model size and computational cost tend to translate to immediate quality gains for most tasks ( as long as enough labeled data is provided for training ) , computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big - data scenarios . Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization .","{'Task': ['big - data scenarios', 'Computer Vision', 'mobile vision'], 'Method': ['deep convolutional networks', 'factorized convolutions', 'aggressive regularization', 'computer vision solutions', 'Inception Architecture', 'Convolutional networks'], 'Material': [], 'Metric': ['computational cost', 'computational efficiency', 'model size', 'low parameter count']}"
0678a8abea82793993cd89383319da75f6dc4be3,"document : ProNet : Learning to Propose Object - specific Boxes for Cascaded Neural Networks This paper aims to classify and locate objects accurately and efficiently , without using bounding box annotations . It is challenging as objects in the wild could appear at arbitrary locations and in different scales . In this paper , we propose a novel classification architecture ProNet based on convolutional neural networks . It uses computationally efficient neural networks to propose image regions that are likely to contain objects , and applies more powerful but slower networks on the proposed regions .",5,"['Task', 'Method', 'Material', 'Metric']","document : ProNet : Learning to Propose Object - specific Boxes for Cascaded Neural Networks This paper aims to classify and locate objects accurately and efficiently , without using bounding box annotations . It is challenging as objects in the wild could appear at arbitrary locations and in different scales . In this paper , we propose a novel classification architecture ProNet based on convolutional neural networks . It uses computationally efficient neural networks to propose image regions that are likely to contain objects , and applies more powerful but slower networks on the proposed regions .","{'Task': [], 'Method': ['convolutional neural networks', 'classification architecture ProNet', 'neural networks', 'ProNet', 'Learning to Propose Object - specific Boxes for Cascaded Neural Networks'], 'Material': [], 'Metric': []}"
081531984770a74e87dbd68907061b4b0f3631bf,"document : Real - Time Video Super - Resolution with Spatio - Temporal Networks and Motion Compensation Convolutional neural networks have enabled accurate image super - resolution in real - time . However , recent attempts to benefit from temporal correlations in video super - resolution have been limited to naive or inefficient architectures . In this paper , we introduce spatio - temporal sub - pixel convolution networks that effectively exploit temporal redundancies and improve reconstruction accuracy while maintaining real - time speed . Specifically , we discuss the use of early fusion , slow fusion and 3D convolutions for the joint processing of multiple consecutive video frames .",5,"['Task', 'Method', 'Material', 'Metric']","document : Real - Time Video Super - Resolution with Spatio - Temporal Networks and Motion Compensation Convolutional neural networks have enabled accurate image super - resolution in real - time . However , recent attempts to benefit from temporal correlations in video super - resolution have been limited to naive or inefficient architectures . In this paper , we introduce spatio - temporal sub - pixel convolution networks that effectively exploit temporal redundancies and improve reconstruction accuracy while maintaining real - time speed . Specifically , we discuss the use of early fusion , slow fusion and 3D convolutions for the joint processing of multiple consecutive video frames .","{'Task': ['Real - Time Video Super - Resolution', 'video super - resolution', 'image super - resolution in real - time', 'video'], 'Method': ['Convolutional neural networks', 'early fusion', 'spatio - temporal sub - pixel convolution networks', 'slow fusion', 'Motion Compensation', 'Spatio - Temporal Networks', '3D convolutions'], 'Material': [], 'Metric': ['real - time speed', 'reconstruction accuracy']}"
0834e74304b547c9354b6d7da6fa78ef47a48fa8,"document : LINE : Large - scale Information Network Embedding This paper studies the problem of embedding very large information networks into low - dimensional vector spaces , which is useful in many tasks such as visualization , node classification , and link prediction . Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes . In this paper , we propose a novel network embedding method called the “ LINE , ” which is suitable for arbitrary types of information networks : undirected , directed , and / or weighted . The method optimizes a carefully designed objective function that preserves both the local and global network structures .",5,"['Task', 'Method', 'Material', 'Metric']","document : LINE : Large - scale Information Network Embedding This paper studies the problem of embedding very large information networks into low - dimensional vector spaces , which is useful in many tasks such as visualization , node classification , and link prediction . Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes . In this paper , we propose a novel network embedding method called the “ LINE , ” which is suitable for arbitrary types of information networks : undirected , directed , and / or weighted . The method optimizes a carefully designed objective function that preserves both the local and global network structures .","{'Task': ['low - dimensional vector spaces', 'link prediction', 'node classification', 'real world information networks', 'information networks', 'embedding very large information networks', 'visualization'], 'Method': ['graph embedding methods', 'objective function', 'LINE', 'Large - scale Information Network Embedding', 'network embedding method'], 'Material': [], 'Metric': []}"
0a3381f0432c5cfe491c718349d7a44e5814592c,"document : Compositional Sequence Labeling Models for Error Detection in Learner Writing In this paper , we present the first experiments using neural network models for the task of error detection in learner writing . We perform a systematic comparison of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs . Experiments on the CoNLL - 14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing . Finally , the model is integrated with a publicly deployed self - assessment system , leading to performance comparable to human annotators .",5,"['Task', 'Method', 'Material', 'Metric']","document : Compositional Sequence Labeling Models for Error Detection in Learner Writing In this paper , we present the first experiments using neural network models for the task of error detection in learner writing . We perform a systematic comparison of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs . Experiments on the CoNLL - 14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing . Finally , the model is integrated with a publicly deployed self - assessment system , leading to performance comparable to human annotators .","{'Task': ['Learner Writing', 'detecting errors in learner writing', 'error detection', 'learner writing', 'Error Detection'], 'Method': ['LSTMs', 'neural network models', 'compositional architectures', 'self - assessment', 'Compositional Sequence Labeling Models'], 'Material': ['CoNLL - 14 shared task dataset'], 'Metric': []}"
0a6c36de8726b6feaab586046ddc1d1a008f44f9,"document : Filtered Channel Features for Pedestrian Detection This paper starts from the observation that multiple top performing pedestrian detectors can be modelled by using an intermediate layer filtering low - level features in combination with a boosted decision forest . Based on this observation we propose a unifying framework and experimentally explore different filter families . We report extensive results enabling a systematic analysis . Using filtered channel features we obtain top performance on the challenging Caltech and KITTI datasets , while using only HOG + LUV as low - level features .",5,"['Task', 'Method', 'Material', 'Metric']","document : Filtered Channel Features for Pedestrian Detection This paper starts from the observation that multiple top performing pedestrian detectors can be modelled by using an intermediate layer filtering low - level features in combination with a boosted decision forest . Based on this observation we propose a unifying framework and experimentally explore different filter families . We report extensive results enabling a systematic analysis . Using filtered channel features we obtain top performance on the challenging Caltech and KITTI datasets , while using only HOG + LUV as low - level features .","{'Task': ['Pedestrian Detection'], 'Method': ['boosted decision forest', 'unifying framework', 'Filtered Channel Features', 'top performing pedestrian detectors', 'intermediate layer filtering low - level features', 'filter families'], 'Material': ['Caltech', 'KITTI'], 'Metric': []}"
0c47cad9729c38d9db1f75491b1ee4bd883a5d4e,"document : Semi - Supervised Sequence Modeling with Cross - View Training kevclark@cs.stanford.edu , thangluong@google.com , manning@cs.stanford.edu , qvl@google.com Unsupervised representation learning algorithms such as word2vec and ELMo improve the accuracy of many supervised NLP models , mainly because they can take advantage of large amounts of unlabeled text . However , the supervised models only learn from task - specific labeled data during the main training phase . We therefore propose Cross - View Training ( CVT ) , a semi - supervised learning algorithm that improves the representations of a Bi - LSTM sentence encoder using a mix of labeled and unlabeled data . On labeled examples , standard supervised learning is used .",5,"['Task', 'Method', 'Material', 'Metric']","document : Semi - Supervised Sequence Modeling with Cross - View Training kevclark@cs.stanford.edu , thangluong@google.com , manning@cs.stanford.edu , qvl@google.com Unsupervised representation learning algorithms such as word2vec and ELMo improve the accuracy of many supervised NLP models , mainly because they can take advantage of large amounts of unlabeled text . However , the supervised models only learn from task - specific labeled data during the main training phase . We therefore propose Cross - View Training ( CVT ) , a semi - supervised learning algorithm that improves the representations of a Bi - LSTM sentence encoder using a mix of labeled and unlabeled data . On labeled examples , standard supervised learning is used .","{'Task': [], 'Method': ['Semi - Supervised Sequence Modeling', 'Unsupervised representation learning algorithms', 'Bi - LSTM sentence encoder', 'semi - supervised learning algorithm', 'CVT', 'supervised models', 'supervised learning', 'Cross - View Training', 'supervised NLP models', 'word2vec', 'ELMo'], 'Material': [], 'Metric': ['accuracy']}"
0dc9eb7d17f2def56ad930945f2521653f04c3fa,Skip - gram Language Modeling Using Sparse Non - negative Matrix Probability Estimation section : Abstract We present a novel family of language model ( LM ) estimation techniques named Sparse Non - negative Matrix ( SNM ) estimation . A first set of experiments empirically evaluating it on the One Billion Word Benchmark [ reference ] shows that SNM n - gram LMs perform almost as well as the well - established Kneser - Ney ( KN ) models .,5,"['Task', 'Method', 'Material', 'Metric']",Skip - gram Language Modeling Using Sparse Non - negative Matrix Probability Estimation section : Abstract We present a novel family of language model ( LM ) estimation techniques named Sparse Non - negative Matrix ( SNM ) estimation . A first set of experiments empirically evaluating it on the One Billion Word Benchmark [ reference ] shows that SNM n - gram LMs perform almost as well as the well - established Kneser - Ney ( KN ) models .,"{'Task': ['Skip - gram Language Modeling'], 'Method': ['SNM n - gram LMs', 'KN', 'LM ) estimation techniques', 'Sparse Non - negative Matrix Probability Estimation', 'Sparse Non - negative Matrix', 'language model', 'Kneser - Ney', 'SNM'], 'Material': ['One Billion Word Benchmark'], 'Metric': []}"
107010b7f2abe3c0c9df62bcef35eb77f6fc76df,"Domain - Adversarial Training of Neural Networks section : Abstract We introduce a new representation learning approach for domain adaptation , in which data at training and test time come from similar but different distributions . Our approach is directly inspired by the theory on domain adaptation suggesting that , for effective domain transfer to be achieved , predictions must be made based on features that can not discriminate between the training ( source ) and test ( target ) domains . The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain ( no labeled target - domain data is necessary ) .",5,"['Task', 'Method', 'Material', 'Metric']","Domain - Adversarial Training of Neural Networks section : Abstract We introduce a new representation learning approach for domain adaptation , in which data at training and test time come from similar but different distributions . Our approach is directly inspired by the theory on domain adaptation suggesting that , for effective domain transfer to be achieved , predictions must be made based on features that can not discriminate between the training ( source ) and test ( target ) domains . The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain ( no labeled target - domain data is necessary ) .","{'Task': ['domain transfer', 'predictions'], 'Method': ['neural network architectures', 'Domain - Adversarial Training of Neural Networks', 'representation learning approach', 'domain adaptation'], 'Material': [], 'Metric': []}"
1130d8fdd931225c2d7563c3808367726cfa1c3a,"document : PixelGAN Autoencoders In this paper , we describe the ‘ ‘ PixelGAN autoencoder ’ ’ , a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels ( PixelCNN ) that is conditioned on a latent code , and the recognition path uses a generative adversarial network ( GAN ) to impose a prior distribution on the latent code . We show that different priors result in different decompositions of information between the latent code and the autoregressive decoder . For example , by imposing a Gaussian distribution as the prior , we can achieve a global vs. local decomposition , or by imposing a categorical distribution as the prior , we can disentangle the style and content information of images in an unsupervised fashion . We further show how the PixelGAN autoencoder with a categorical prior can be directly used in semi - supervised settings and achieve competitive semi - supervised classification results on the MNIST , SVHN and NORB datasets .",5,"['Task', 'Method', 'Material', 'Metric']","document : PixelGAN Autoencoders In this paper , we describe the ‘ ‘ PixelGAN autoencoder ’ ’ , a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels ( PixelCNN ) that is conditioned on a latent code , and the recognition path uses a generative adversarial network ( GAN ) to impose a prior distribution on the latent code . We show that different priors result in different decompositions of information between the latent code and the autoregressive decoder . For example , by imposing a Gaussian distribution as the prior , we can achieve a global vs. local decomposition , or by imposing a categorical distribution as the prior , we can disentangle the style and content information of images in an unsupervised fashion . We further show how the PixelGAN autoencoder with a categorical prior can be directly used in semi - supervised settings and achieve competitive semi - supervised classification results on the MNIST , SVHN and NORB datasets .","{'Task': ['competitive semi - supervised classification', 'semi - supervised settings'], 'Method': ['unsupervised fashion', 'recognition path', 'autoregressive decoder', 'GAN', 'Gaussian distribution', 'convolutional autoregressive neural network on pixels', 'autoencoder', 'PixelGAN Autoencoders', 'generative path', 'PixelCNN', 'generative adversarial network', 'generative autoencoder'], 'Material': ['MNIST'], 'Metric': []}"
11356cd6bb0f2776a88cd584ff108470414c6594,"document : Submanifold Sparse Convolutional Networks Convolutional network are the de - facto standard for analysing spatio - temporal data such as images , videos , 3D shapes , etc . Whilst some of this data is naturally dense ( for instance , photos ) , many other data sources are inherently sparse . Examples include pen - strokes forming on a piece of paper , or ( colored ) 3D point clouds that were obtained using a LiDAR scanner or RGB - D camera . Standard",5,"['Task', 'Method', 'Material', 'Metric']","document : Submanifold Sparse Convolutional Networks Convolutional network are the de - facto standard for analysing spatio - temporal data such as images , videos , 3D shapes , etc . Whilst some of this data is naturally dense ( for instance , photos ) , many other data sources are inherently sparse . Examples include pen - strokes forming on a piece of paper , or ( colored ) 3D point clouds that were obtained using a LiDAR scanner or RGB - D camera . Standard","{'Task': [], 'Method': ['Submanifold Sparse Convolutional Networks', 'RGB - D camera', 'LiDAR scanner', 'Convolutional network'], 'Material': [], 'Metric': []}"
11da0c54ba904a1cb31a09d10da55f73e8825c61,"document : Natural Language Inference by Tree - Based Convolution and Heuristic Matching In this paper , we propose the TBCNN - pair model to recognize entailment and contradiction between two sentences . In our model , a tree - based convolutional neural network ( TBCNN ) captures sentence - level semantics ; then heuristic matching layers like concatenation , element - wise product / difference combine the information in individual sentences . Experimental results show that our model outperforms existing sentence encoding - based approaches by a large margin . section : Introduction",5,"['Task', 'Method', 'Material', 'Metric']","document : Natural Language Inference by Tree - Based Convolution and Heuristic Matching In this paper , we propose the TBCNN - pair model to recognize entailment and contradiction between two sentences . In our model , a tree - based convolutional neural network ( TBCNN ) captures sentence - level semantics ; then heuristic matching layers like concatenation , element - wise product / difference combine the information in individual sentences . Experimental results show that our model outperforms existing sentence encoding - based approaches by a large margin . section : Introduction","{'Task': ['recognize entailment and contradiction', 'Natural Language Inference'], 'Method': ['sentence encoding - based approaches', 'concatenation', 'Heuristic Matching', 'TBCNN - pair model', 'Tree - Based Convolution', 'TBCNN', 'tree - based convolutional neural network', 'heuristic matching layers'], 'Material': [], 'Metric': []}"
1235dd37312cb20aced0e97d953f6379d8a0c7d4,"document : Grounded Textual Entailment Capturing semantic relations between sentences , such as entailment , is a long - standing challenge for computational semantics . Logic - based models analyse entailment in terms of possible worlds ( interpretations , or situations ) where a premise P entails a hypothesis H iff in all worlds where P is true , H is also true . Statistical models view this relationship probabilistically , addressing it in terms of whether a human would likely infer H from P. In this paper , we wish to bridge these two perspectives , by arguing for a visually - grounded version of the Textual Entailment task .",5,"['Task', 'Method', 'Material', 'Metric']","document : Grounded Textual Entailment Capturing semantic relations between sentences , such as entailment , is a long - standing challenge for computational semantics . Logic - based models analyse entailment in terms of possible worlds ( interpretations , or situations ) where a premise P entails a hypothesis H iff in all worlds where P is true , H is also true . Statistical models view this relationship probabilistically , addressing it in terms of whether a human would likely infer H from P. In this paper , we wish to bridge these two perspectives , by arguing for a visually - grounded version of the Textual Entailment task .","{'Task': ['Grounded Textual Entailment', 'computational semantics', 'Textual Entailment task', 'Capturing semantic relations between sentences'], 'Method': ['Statistical models', 'Logic - based models', 'visually - grounded version'], 'Material': [], 'Metric': []}"
14318685b5959b51d0f1e3db34643eb2855dc6d9,"document : Going deeper with convolutions We propose a deep convolutional neural network architecture codenamed âInceptionâ , which was responsible for setting the new state of the art for classification and detection in the ImageNet Large - Scale Visual Recognition Challenge 2014 ( ILSVRCâ14 ) . The main hallmark of this architecture is the improved utilization of the computing resources inside the network . This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant . To optimize quality , the architectural decisions were based on the Hebbian principle and the intuition of multi - scale processing .",5,"['Task', 'Method', 'Material', 'Metric']","document : Going deeper with convolutions We propose a deep convolutional neural network architecture codenamed âInceptionâ , which was responsible for setting the new state of the art for classification and detection in the ImageNet Large - Scale Visual Recognition Challenge 2014 ( ILSVRCâ14 ) . The main hallmark of this architecture is the improved utilization of the computing resources inside the network . This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant . To optimize quality , the architectural decisions were based on the Hebbian principle and the intuition of multi - scale processing .","{'Task': ['classification', 'detection', 'ImageNet Large - Scale Visual Recognition Challenge 2014', 'ILSVRCâ\x80\x9914'], 'Method': ['deep convolutional neural network architecture codenamed â\x80\x9cInceptionâ\x80\x9d', 'intuition of multi - scale processing', 'convolutions', 'Hebbian principle'], 'Material': [], 'Metric': ['quality']}"
16051bbe3a7f7c77a952ebf76722ea655e8906ca,"Image Super - resolution via Feature - augmented Random Forest section : Abstract - Recent random - forest ( RF )- based image super - resolution approaches inherit some properties from dictionary - learning - based algorithms , but the effectiveness of the properties in RF is overlooked in the literature . In this paper , we present a novel feature - augmented random forest ( FARF ) for image super - resolution , where the conventional gradient - based features are augmented with gradient magnitudes and different feature recipes are formulated on different stages in an RF . The advantages of our method are that , firstly , the dictionary - learning - based features are enhanced by adding gradient magnitudes , based on the observation that the non - linear gradient magnitude are with highly discriminative property .",5,"['Task', 'Method', 'Material', 'Metric']","Image Super - resolution via Feature - augmented Random Forest section : Abstract - Recent random - forest ( RF )- based image super - resolution approaches inherit some properties from dictionary - learning - based algorithms , but the effectiveness of the properties in RF is overlooked in the literature . In this paper , we present a novel feature - augmented random forest ( FARF ) for image super - resolution , where the conventional gradient - based features are augmented with gradient magnitudes and different feature recipes are formulated on different stages in an RF . The advantages of our method are that , firstly , the dictionary - learning - based features are enhanced by adding gradient magnitudes , based on the observation that the non - linear gradient magnitude are with highly discriminative property .","{'Task': ['image super - resolution', 'Image Super - resolution'], 'Method': ['Recent random - forest', 'dictionary - learning - based features', 'RF', 'dictionary - learning - based algorithms', 'FARF', 'feature - augmented random forest', 'gradient - based features', 'Feature - augmented Random Forest'], 'Material': [], 'Metric': []}"
160563abbd75265b19afc8b4169bab9e1eb33d97,"document : Massively Multilingual Sentence Embeddings for Zero - Shot Cross - Lingual Transfer and Beyond We introduce an architecture to learn joint multilingual sentence representations for 93 languages , belonging to more than 30 different language families and written in 28 different scripts . Our system uses a single BiLSTM encoder with a shared BPE vocabulary for all languages , which is coupled with an auxiliary decoder and trained on publicly available parallel corpora . This enables us to learn a classifier on top of the resulting sentence embeddings using English annotated data only , and transfer it to any of the 93 languages without any modification . Our approach sets a new state - of - the - art on zero - shot cross - lingual natural language inference for all the 14 languages in the XNLI dataset but one .",5,"['Task', 'Method', 'Material', 'Metric']","document : Massively Multilingual Sentence Embeddings for Zero - Shot Cross - Lingual Transfer and Beyond We introduce an architecture to learn joint multilingual sentence representations for 93 languages , belonging to more than 30 different language families and written in 28 different scripts . Our system uses a single BiLSTM encoder with a shared BPE vocabulary for all languages , which is coupled with an auxiliary decoder and trained on publicly available parallel corpora . This enables us to learn a classifier on top of the resulting sentence embeddings using English annotated data only , and transfer it to any of the 93 languages without any modification . Our approach sets a new state - of - the - art on zero - shot cross - lingual natural language inference for all the 14 languages in the XNLI dataset but one .","{'Task': ['Massively Multilingual Sentence Embeddings', 'sentence representations', 'Zero - Shot Cross - Lingual Transfer', 'cross - lingual natural language inference'], 'Method': ['auxiliary decoder', 'sentence embeddings', 'BiLSTM encoder', 'BPE', 'classifier'], 'Material': ['XNLI dataset'], 'Metric': []}"
175f74a09241b6cb5101a2a09978095720db7d5f,"document : Image Super - Resolution via Dual - State Recurrent Networks Advances in image super - resolution ( SR ) have recently benefited significantly from rapid developments in deep neural networks . Inspired by these recent discoveries , we note that many state - of - the - art deep SR architectures can be reformulated as a single - state recurrent neural network ( RNN ) with finite unfoldings . In this paper , we explore new structures for SR based on this compact RNN view , leading us to a dual - state design , the Dual - State Recurrent Network ( DSRN ) . Compared to its single - state counterparts that operate at a fixed spatial resolution , DSRN exploits both low - resolution ( LR ) and high - resolution ( HR ) signals jointly .",5,"['Task', 'Method', 'Material', 'Metric']","document : Image Super - Resolution via Dual - State Recurrent Networks Advances in image super - resolution ( SR ) have recently benefited significantly from rapid developments in deep neural networks . Inspired by these recent discoveries , we note that many state - of - the - art deep SR architectures can be reformulated as a single - state recurrent neural network ( RNN ) with finite unfoldings . In this paper , we explore new structures for SR based on this compact RNN view , leading us to a dual - state design , the Dual - State Recurrent Network ( DSRN ) . Compared to its single - state counterparts that operate at a fixed spatial resolution , DSRN exploits both low - resolution ( LR ) and high - resolution ( HR ) signals jointly .","{'Task': ['image super - resolution', 'Image Super - Resolution', 'HR', 'high - resolution', 'SR'], 'Method': ['finite unfoldings', 'deep neural networks', 'single - state recurrent neural network', 'compact RNN view', 'Dual - State Recurrent Network', 'DSRN', 'Dual - State Recurrent Networks', 'dual - state design', 'RNN'], 'Material': [], 'Metric': []}"
1778e32c18bd611169e64c1805a51abff341ca53,"document : Natural Language Inference over Interaction Space Natural Language Inference ( NLI ) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis . We introduce Interactive Inference Network ( IIN ) , a novel class of neural network architectures that is able to achieve high - level understanding of the sentence pair by hierarchically extracting semantic features from interaction space . We show that an interaction tensor ( attention weight ) contains semantic information to solve natural language inference , and a denser interaction tensor contains richer semantic information . One instance of such architecture , Densely Interactive Inference Network ( DIIN ) , demonstrates the state - of - the - art performance on large scale NLI copora and large - scale NLI alike corpus .",5,"['Task', 'Method', 'Material', 'Metric']","document : Natural Language Inference over Interaction Space Natural Language Inference ( NLI ) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis . We introduce Interactive Inference Network ( IIN ) , a novel class of neural network architectures that is able to achieve high - level understanding of the sentence pair by hierarchically extracting semantic features from interaction space . We show that an interaction tensor ( attention weight ) contains semantic information to solve natural language inference , and a denser interaction tensor contains richer semantic information . One instance of such architecture , Densely Interactive Inference Network ( DIIN ) , demonstrates the state - of - the - art performance on large scale NLI copora and large - scale NLI alike corpus .","{'Task': ['Interaction Space', 'NLI', 'natural language inference', 'Natural Language Inference'], 'Method': ['DIIN', 'Densely Interactive Inference Network', 'IIN )', 'Interactive Inference Network', 'neural network architectures'], 'Material': [], 'Metric': []}"
178275dbdcfa267e41a9d5efe386ee5874c6d23f,"document : Fraternal Dropout Recurrent neural networks ( RNNs ) form an important class of architectures among neural networks useful for language modeling and sequential prediction . However , optimizing RNNs is known to be harder compared to feed - forward neural networks . A number of techniques have been proposed in literature to address this problem . In this paper we propose a simple technique called fraternal dropout that takes advantage of dropout to achieve this goal .",5,"['Task', 'Method', 'Material', 'Metric']","document : Fraternal Dropout Recurrent neural networks ( RNNs ) form an important class of architectures among neural networks useful for language modeling and sequential prediction . However , optimizing RNNs is known to be harder compared to feed - forward neural networks . A number of techniques have been proposed in literature to address this problem . In this paper we propose a simple technique called fraternal dropout that takes advantage of dropout to achieve this goal .","{'Task': ['optimizing RNNs', 'language modeling', 'sequential prediction'], 'Method': ['Recurrent neural networks', 'RNNs', 'feed - forward neural networks', 'neural networks', 'fraternal dropout', 'dropout'], 'Material': [], 'Metric': []}"
178631e0f0e624b1607c7a7a2507ed30d4e83a42,"document : Speech Recognition with Deep Recurrent Neural Networks Recurrent neural networks ( RNNs ) are a powerful model for sequential data . End - to - end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input - output alignment is unknown . The combination of these methods with the Long Short - term Memory RNN architecture has proved particularly fruitful , delivering state - of - the - art results in cursive handwriting recognition . However RNN performance in speech recognition has so far been disappointing , with better results returned by deep feedforward networks .",5,"['Task', 'Method', 'Material', 'Metric']","document : Speech Recognition with Deep Recurrent Neural Networks Recurrent neural networks ( RNNs ) are a powerful model for sequential data . End - to - end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input - output alignment is unknown . The combination of these methods with the Long Short - term Memory RNN architecture has proved particularly fruitful , delivering state - of - the - art results in cursive handwriting recognition . However RNN performance in speech recognition has so far been disappointing , with better results returned by deep feedforward networks .","{'Task': ['sequence labelling problems', 'Speech Recognition', 'handwriting recognition', 'speech'], 'Method': ['Connectionist Temporal Classification', 'Recurrent neural networks', 'deep feedforward networks', 'RNNs', 'end training methods', 'Deep Recurrent Neural Networks', 'RNN', 'Long Short - term Memory RNN architecture'], 'Material': [], 'Metric': []}"
18168aea48a22f6fe2fe407c0ff70083cba225a7,"document : Image Restoration Using Very Deep Convolutional Encoder - Decoder Networks with Symmetric Skip Connections In this paper , we propose a very deep fully convolutional encoding - decoding framework for image restoration such as denoising and super - resolution . The network is composed of multiple layers of convolution and de - convolution operators , learning end - to - end mappings from corrupted images to the original ones . The convolutional layers act as the feature extractor , which capture the abstraction of image contents while eliminating noises / corruptions . De - convolutional layers are then used to recover the image details .",5,"['Task', 'Method', 'Material', 'Metric']","document : Image Restoration Using Very Deep Convolutional Encoder - Decoder Networks with Symmetric Skip Connections In this paper , we propose a very deep fully convolutional encoding - decoding framework for image restoration such as denoising and super - resolution . The network is composed of multiple layers of convolution and de - convolution operators , learning end - to - end mappings from corrupted images to the original ones . The convolutional layers act as the feature extractor , which capture the abstraction of image contents while eliminating noises / corruptions . De - convolutional layers are then used to recover the image details .","{'Task': ['image restoration', 'super - resolution', 'denoising', 'Image Restoration'], 'Method': ['Symmetric Skip Connections', 'convolutional layers', 'Deep Convolutional Encoder - Decoder Networks', 'deep fully convolutional encoding - decoding framework', 'De - convolutional layers', 'feature extractor', 'layers of convolution and de - convolution operators'], 'Material': [], 'Metric': []}"
193089d56758ab88391d846edd08d359b1f9a863,"document : A Discriminatively Learned CNN Embedding for Person Re - identification In this paper , we revisit two popular convolutional neural networks ( CNN ) in person re - identification ( re - ID ) , i.e. , verification and identification models . The two models have their respective advantages and limitations due to different loss functions . In this paper , we shed light on how to combine the two models to learn more discriminative pedestrian descriptors . Specifically , we propose a siamese network that simultaneously computes the identification loss and verification loss .",5,"['Task', 'Method', 'Material', 'Metric']","document : A Discriminatively Learned CNN Embedding for Person Re - identification In this paper , we revisit two popular convolutional neural networks ( CNN ) in person re - identification ( re - ID ) , i.e. , verification and identification models . The two models have their respective advantages and limitations due to different loss functions . In this paper , we shed light on how to combine the two models to learn more discriminative pedestrian descriptors . Specifically , we propose a siamese network that simultaneously computes the identification loss and verification loss .","{'Task': ['discriminative pedestrian descriptors', 'verification', 'Person Re - identification', 'identification models', 'person re - identification', 're - ID'], 'Method': ['siamese network', 'Discriminatively Learned CNN Embedding', 'CNN', 'convolutional neural networks'], 'Material': [], 'Metric': ['identification loss']}"
193b518bc3025804c6d587c74cbc154d91478417,"document : Learning to Adapt Structured Output Space for Semantic Segmentation Convolutional neural network - based approaches for semantic segmentation rely on supervision with pixel - level ground truth , but may not generalize well to unseen image domains . As the labeling process is tedious and labor intensive , developing algorithms that can adapt source ground truth labels to the target domain is of great interest . In this paper , we propose an adversarial learning method for domain adaptation in the context of semantic segmentation . Considering semantic segmentations as structured outputs that contain spatial similarities between the source and target domains , we adopt adversarial learning in the output space .",5,"['Task', 'Method', 'Material', 'Metric']","document : Learning to Adapt Structured Output Space for Semantic Segmentation Convolutional neural network - based approaches for semantic segmentation rely on supervision with pixel - level ground truth , but may not generalize well to unseen image domains . As the labeling process is tedious and labor intensive , developing algorithms that can adapt source ground truth labels to the target domain is of great interest . In this paper , we propose an adversarial learning method for domain adaptation in the context of semantic segmentation . Considering semantic segmentations as structured outputs that contain spatial similarities between the source and target domains , we adopt adversarial learning in the output space .","{'Task': ['semantic segmentation', 'Semantic Segmentation', 'labeling process', 'semantic segmentations'], 'Method': ['adversarial learning', 'Convolutional neural network - based approaches', 'adversarial learning method', 'domain adaptation'], 'Material': [], 'Metric': []}"
1d0dcb458aa4d30b51f7c74b159be687f39120a0,"document : Pose - driven Deep Convolutional Model for Person Re - identification Feature extraction and matching are two crucial components in person Re - Identification ( ReID ) . The large pose deformations and the complex view variations exhibited by the captured person images significantly increase the difficulty of learning and matching of the features from person images . To overcome these difficulties , in this work we propose a Pose - driven Deep Convolutional ( PDC ) model to learn improved feature extraction and matching models from end to end . Our deep architecture explicitly leverages the human part cues to alleviate the pose variations and learn robust feature representations from both the global image and different local parts .",5,"['Task', 'Method', 'Material', 'Metric']","document : Pose - driven Deep Convolutional Model for Person Re - identification Feature extraction and matching are two crucial components in person Re - Identification ( ReID ) . The large pose deformations and the complex view variations exhibited by the captured person images significantly increase the difficulty of learning and matching of the features from person images . To overcome these difficulties , in this work we propose a Pose - driven Deep Convolutional ( PDC ) model to learn improved feature extraction and matching models from end to end . Our deep architecture explicitly leverages the human part cues to alleviate the pose variations and learn robust feature representations from both the global image and different local parts .","{'Task': ['learning and matching of the features', 'matching', 'person Re - Identification', 'ReID', 'Person Re - identification', 'Feature extraction'], 'Method': ['deep architecture', 'PDC', 'robust feature representations', 'feature extraction', 'Pose - driven Deep Convolutional', 'matching models'], 'Material': [], 'Metric': []}"
1f08598381af9146d0fd9a61b30d0e51a7331689,"document : Distributed Prioritized Experience Replay We propose a distributed architecture for deep reinforcement learning at scale , that enables agents to learn effectively from orders of magnitude more data than previously possible . The algorithm decouples acting from learning : the actors interact with their own instances of the environment by selecting actions according to a shared neural network , and accumulate the resulting experience in a shared experience replay memory ; the learner replays samples of experience and updates the neural network . The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors . Our architecture substantially improves the state of the art on the Arcade Learning Environment , achieving better final performance in a fraction of the wall - clock training time .",5,"['Task', 'Method', 'Material', 'Metric']","document : Distributed Prioritized Experience Replay We propose a distributed architecture for deep reinforcement learning at scale , that enables agents to learn effectively from orders of magnitude more data than previously possible . The algorithm decouples acting from learning : the actors interact with their own instances of the environment by selecting actions according to a shared neural network , and accumulate the resulting experience in a shared experience replay memory ; the learner replays samples of experience and updates the neural network . The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors . Our architecture substantially improves the state of the art on the Arcade Learning Environment , achieving better final performance in a fraction of the wall - clock training time .","{'Task': ['Distributed Prioritized Experience Replay', 'deep reinforcement learning', 'learning', 'prioritized experience replay'], 'Method': ['shared neural network', 'distributed architecture', 'neural network'], 'Material': ['Arcade Learning Environment'], 'Metric': ['wall - clock training time']}"
2138a7127429d67746ec78de46d6820fee0e548e,"document : Graph2Seq : Graph to Sequence Learning with Attention - Based Neural Networks The celebrated Sequence to Sequence learning ( Seq2Seq ) technique and its numerous variants achieve excellent performance on many tasks . However , many machine learning tasks have inputs naturally represented as graphs ; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence . To address this challenge , we introduce a novel general end - to - end graph - to - sequence neural encoder - decoder model that maps an input graph to a sequence of vectors and uses an attention - based LSTM method to decode the target sequence from these vectors . Our method first generates the node and graph embeddings using an improved graph - based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings .",5,"['Task', 'Method', 'Material', 'Metric']","document : Graph2Seq : Graph to Sequence Learning with Attention - Based Neural Networks The celebrated Sequence to Sequence learning ( Seq2Seq ) technique and its numerous variants achieve excellent performance on many tasks . However , many machine learning tasks have inputs naturally represented as graphs ; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence . To address this challenge , we introduce a novel general end - to - end graph - to - sequence neural encoder - decoder model that maps an input graph to a sequence of vectors and uses an attention - based LSTM method to decode the target sequence from these vectors . Our method first generates the node and graph embeddings using an improved graph - based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings .","{'Task': ['conversion', 'machine learning tasks', 'Graph to Sequence Learning'], 'Method': ['LSTM', 'node and graph embeddings', 'graph - based neural network', 'Seq2Seq', 'end - to - end graph - to - sequence neural encoder - decoder model', 'aggregation strategy', 'Sequence to Sequence learning', 'Attention - Based Neural Networks', 'Graph2Seq'], 'Material': [], 'Metric': []}"
21a1654b856cf0c64e60e58258669b374cb05539,"document : You Only Look Once : Unified , Real - Time Object Detection We present YOLO , a new approach to object detection . Prior work on object detection repurposes classifiers to perform detection . Instead , we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities . A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation .",5,"['Task', 'Method', 'Material', 'Metric']","document : You Only Look Once : Unified , Real - Time Object Detection We present YOLO , a new approach to object detection . Prior work on object detection repurposes classifiers to perform detection . Instead , we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities . A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation .","{'Task': ['Real - Time Object Detection', 'regression problem', 'detection', 'object detection'], 'Method': ['neural network', 'classifiers', 'YOLO'], 'Material': [], 'Metric': []}"
232b43584b2236669c0a53702ad89ab10c3886ea,"In this work , we build on recent advances in distributional reinforcement learning to give a generally applicable , flexible , and state - of - the - art distributional variant of DQN . We achieve this by using quantile regression to approximate the full quantile function for the state - action return distribution . By reparameterizing a distribution over the sample space , this yields an implicitly defined return distribution and gives rise to a large class of risk - sensitive policies . We demonstrate improved performance on the 57 Atari 2600 games in the ALE , and use our algorithm ’s implicitly defined distributions to study the effects of risk - sensitive policies in Atari games . ImplicitQuantileNetworksforDistributionalReinforcementLearning",5,"['Task', 'Method', 'Material', 'Metric']","In this work , we build on recent advances in distributional reinforcement learning to give a generally applicable , flexible , and state - of - the - art distributional variant of DQN . We achieve this by using quantile regression to approximate the full quantile function for the state - action return distribution . By reparameterizing a distribution over the sample space , this yields an implicitly defined return distribution and gives rise to a large class of risk - sensitive policies . We demonstrate improved performance on the 57 Atari 2600 games in the ALE , and use our algorithm ’s implicitly defined distributions to study the effects of risk - sensitive policies in Atari games . ImplicitQuantileNetworksforDistributionalReinforcementLearning","{'Task': ['risk - sensitive policies', 'Atari games'], 'Method': ['risk - sensitive policies', 'distributional variant', 'reinforcement learning', 'quantile regression', 'DQN'], 'Material': ['Atari 2600 games'], 'Metric': []}"
23d2d3a6ffebfecaa8930307fdcf451c147757c8,"document : SeqGAN : Sequence Generative Adversarial Nets with Policy Gradient As a new way of training generative models , Generative Adversarial Net ( GAN ) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real - valued data . However , it has limitations when the goal is for generating sequences of discrete tokens . A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model . Also , the discriminative model can only assess a complete sequence , while for a partially generated sequence , it is non - trivial to balance its current score and the future one once the entire sequence has been generated .",5,"['Task', 'Method', 'Material', 'Metric']","document : SeqGAN : Sequence Generative Adversarial Nets with Policy Gradient As a new way of training generative models , Generative Adversarial Net ( GAN ) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real - valued data . However , it has limitations when the goal is for generating sequences of discrete tokens . A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model . Also , the discriminative model can only assess a complete sequence , while for a partially generated sequence , it is non - trivial to balance its current score and the future one once the entire sequence has been generated .","{'Task': ['generating sequences of discrete tokens'], 'Method': ['generative models', 'discriminative model', 'Sequence Generative Adversarial Nets', 'generative model', 'Policy Gradient', 'Generative Adversarial Net', 'GAN', 'SeqGAN'], 'Material': [], 'Metric': []}"
24730424236724d3f798dec02901e7a1f1c4710e,"Joint Maximum Purity Forest with Application to Image Super - Resolution section : Abstract - In this paper , we propose a novel random - forest scheme , namely Joint Maximum Purity Forest ( JMPF ) , for classification , clustering , and regression tasks . In the JMPF scheme , the original feature space is transformed into a compactly pre - clustered feature space , via a trained rotation matrix . The rotation matrix is obtained through an iterative quantization process , where the input data belonging to different classes are clustered to the respective vertices of the new feature space with maximum purity .",5,"['Task', 'Method', 'Material', 'Metric']","Joint Maximum Purity Forest with Application to Image Super - Resolution section : Abstract - In this paper , we propose a novel random - forest scheme , namely Joint Maximum Purity Forest ( JMPF ) , for classification , clustering , and regression tasks . In the JMPF scheme , the original feature space is transformed into a compactly pre - clustered feature space , via a trained rotation matrix . The rotation matrix is obtained through an iterative quantization process , where the input data belonging to different classes are clustered to the respective vertices of the new feature space with maximum purity .","{'Task': ['Image Super - Resolution', 'classification , clustering , and regression tasks'], 'Method': ['Joint Maximum Purity Forest', 'iterative quantization process', 'random - forest scheme', 'JMPF'], 'Material': [], 'Metric': []}"
249b3b7421d3cdb932eecfe4b67203e0e46806b2,"document : Cell - aware Stacked LSTMs for Modeling Sentences We propose a method of stacking multiple long short - term memory ( LSTM ) layers for modeling sentences . In contrast to the conventional stacked LSTMs where only hidden states are fed as input to the next layer , our architecture accepts both hidden and memory cell states of the preceding layer and fuses information from the left and the lower context using the soft gating mechanism of LSTMs . Thus the proposed stacked LSTM architecture modulates the amount of information to be delivered not only in horizontal recurrence but also in vertical connections , from which useful features extracted from lower layers are effectively conveyed to upper layers . We dub this architecture Cell - aware Stacked LSTM ( CAS - LSTM ) and show from experiments that our models achieve state - of - the - art results on benchmark datasets for natural language inference , paraphrase detection , and sentiment classification .",5,"['Task', 'Method', 'Material', 'Metric']","document : Cell - aware Stacked LSTMs for Modeling Sentences We propose a method of stacking multiple long short - term memory ( LSTM ) layers for modeling sentences . In contrast to the conventional stacked LSTMs where only hidden states are fed as input to the next layer , our architecture accepts both hidden and memory cell states of the preceding layer and fuses information from the left and the lower context using the soft gating mechanism of LSTMs . Thus the proposed stacked LSTM architecture modulates the amount of information to be delivered not only in horizontal recurrence but also in vertical connections , from which useful features extracted from lower layers are effectively conveyed to upper layers . We dub this architecture Cell - aware Stacked LSTM ( CAS - LSTM ) and show from experiments that our models achieve state - of - the - art results on benchmark datasets for natural language inference , paraphrase detection , and sentiment classification .","{'Task': ['natural language inference', 'paraphrase detection', 'modeling sentences', 'sentiment classification', 'Modeling Sentences'], 'Method': ['LSTMs', 'Cell - aware Stacked LSTM', 'LSTM', 'CAS - LSTM', 'multiple long short - term memory', 'soft gating mechanism'], 'Material': [], 'Metric': []}"
25a784f7f8c94c42821ee078587fc38dffcd00a4,"document : Robust Face Detection via Learning Small Faces on Hard Images Recent anchor - based deep face detectors have achieved promising performance , but they are still struggling to detect hard faces , such as small , blurred and partially occluded faces . A reason is that they treat all images and faces equally , without putting more effort on hard ones ; however , many training images only contain easy faces , which are less helpful to achieve better performance on hard images . In this paper , we propose that the robustness of a face detector against hard faces can be improved by learning small faces on hard images . Our intuitions are ( 1 ) hard images are the images which contain at least one hard face , thus they facilitate training robust face detectors ; ( 2 ) most hard faces are small faces and other types of hard faces can be easily converted to small faces by shrinking .",5,"['Task', 'Method', 'Material', 'Metric']","document : Robust Face Detection via Learning Small Faces on Hard Images Recent anchor - based deep face detectors have achieved promising performance , but they are still struggling to detect hard faces , such as small , blurred and partially occluded faces . A reason is that they treat all images and faces equally , without putting more effort on hard ones ; however , many training images only contain easy faces , which are less helpful to achieve better performance on hard images . In this paper , we propose that the robustness of a face detector against hard faces can be improved by learning small faces on hard images . Our intuitions are ( 1 ) hard images are the images which contain at least one hard face , thus they facilitate training robust face detectors ; ( 2 ) most hard faces are small faces and other types of hard faces can be easily converted to small faces by shrinking .","{'Task': ['Learning Small Faces', 'Robust Face Detection'], 'Method': ['face detectors', 'anchor - based deep face detectors', 'face detector'], 'Material': ['Hard Images', 'hard images'], 'Metric': ['robustness']}"
25f5df29342a04936ba0d308b4d1b8245a7e8f5c,Convolutional Pose Machines section : Abstract Pose Machines provide a sequential prediction framework for learning rich implicit spatial models . In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image - dependent spatial models for the task of pose estimation . The contribution of this paper is to implicitly model long - range dependencies between variables in structured prediction tasks such as articulated pose estimation .,5,"['Task', 'Method', 'Material', 'Metric']",Convolutional Pose Machines section : Abstract Pose Machines provide a sequential prediction framework for learning rich implicit spatial models . In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image - dependent spatial models for the task of pose estimation . The contribution of this paper is to implicitly model long - range dependencies between variables in structured prediction tasks such as articulated pose estimation .,"{'Task': ['structured prediction tasks', 'long - range dependencies between variables', 'learning image features', 'pose estimation'], 'Method': ['Convolutional Pose Machines', 'convolutional networks', 'Pose Machines', 'sequential prediction framework', 'image - dependent spatial models', 'pose machine', 'implicit spatial models'], 'Material': [], 'Metric': []}"
269730dbbabed8b8b5ba720e44a4c31b1f51e8f1,"Published as a conference paper at ICLR 2017 QUERY - REDUCTION NETWORKS FOR QUESTION ANSWERING section : ABSTRACT In this paper , we study the problem of question answering when reasoning over multiple facts is required . We propose Query - Reduction Network ( QRN ) , a variant of Recurrent Neural Network ( RNN ) that effectively handles both short - term ( local ) and long - term ( global ) sequential dependencies to reason over multiple facts . QRN considers the context sentences as a sequence of state - changing triggers , and reduces the original query to a more informed query as it observes each trigger ( context sentence ) through time .",5,"['Task', 'Method', 'Material', 'Metric']","Published as a conference paper at ICLR 2017 QUERY - REDUCTION NETWORKS FOR QUESTION ANSWERING section : ABSTRACT In this paper , we study the problem of question answering when reasoning over multiple facts is required . We propose Query - Reduction Network ( QRN ) , a variant of Recurrent Neural Network ( RNN ) that effectively handles both short - term ( local ) and long - term ( global ) sequential dependencies to reason over multiple facts . QRN considers the context sentences as a sequence of state - changing triggers , and reduces the original query to a more informed query as it observes each trigger ( context sentence ) through time .","{'Task': ['QUESTION ANSWERING', 'question answering'], 'Method': ['QUERY - REDUCTION NETWORKS', 'QRN', 'Query - Reduction Network', 'Recurrent Neural Network', 'RNN'], 'Material': [], 'Metric': []}"
270e65acc071b9e4e2a632720130c0e10cb6fa08,"document : Neural Tree Indexers for Text Understanding Recurrent neural networks ( RNNs ) process input text sequentially and model the conditional transition between word tokens . In contrast , the advantages of recursive networks include that they explicitly model the compositionality and the recursive structure of natural language . However , the current recursive architecture is limited by its dependence on syntactic tree . In this paper , we introduce a robust syntactic parsing - independent tree structured model , Neural Tree Indexers ( NTI ) that provides a middle ground between the sequential RNNs and the syntactic tree - based recursive models .",5,"['Task', 'Method', 'Material', 'Metric']","document : Neural Tree Indexers for Text Understanding Recurrent neural networks ( RNNs ) process input text sequentially and model the conditional transition between word tokens . In contrast , the advantages of recursive networks include that they explicitly model the compositionality and the recursive structure of natural language . However , the current recursive architecture is limited by its dependence on syntactic tree . In this paper , we introduce a robust syntactic parsing - independent tree structured model , Neural Tree Indexers ( NTI ) that provides a middle ground between the sequential RNNs and the syntactic tree - based recursive models .","{'Task': ['Text Understanding'], 'Method': ['tree', 'Recurrent neural networks', 'Neural Tree Indexers', 'RNNs', 'NTI', 'recursive networks', 'recursive architecture'], 'Material': [], 'Metric': []}"
2777cd26b2c257843273fe41ad4c5b8cdf1b1b75,"document : Understanding Humans in Crowded Scenes : Deep Nested Adversarial Learning and A New Benchmark for Multi - Human Parsing Despite the noticeable progress in perceptual tasks like detection , instance segmentation and human parsing , computers still perform unsatisfactorily on visually understanding humans in crowded scenes , such as group behavior analysis , person re - identification and autonomous driving , etc . To this end , models need to comprehensively perceive the semantic information and the differences between instances in a multi - human image , which is recently defined as the multi - human parsing task . In this paper , we present a new large - scale database “ M ulti - H uman",5,"['Task', 'Method', 'Material', 'Metric']","document : Understanding Humans in Crowded Scenes : Deep Nested Adversarial Learning and A New Benchmark for Multi - Human Parsing Despite the noticeable progress in perceptual tasks like detection , instance segmentation and human parsing , computers still perform unsatisfactorily on visually understanding humans in crowded scenes , such as group behavior analysis , person re - identification and autonomous driving , etc . To this end , models need to comprehensively perceive the semantic information and the differences between instances in a multi - human image , which is recently defined as the multi - human parsing task . In this paper , we present a new large - scale database “ M ulti - H uman","{'Task': ['autonomous driving', 'detection', 'instance segmentation', 'group behavior analysis', 'Understanding Humans in Crowded Scenes', 'human parsing', 'visually understanding humans in crowded scenes', 'perceptual tasks', 'person re - identification', 'Multi - Human Parsing', 'M ulti -'], 'Method': ['Deep Nested Adversarial Learning'], 'Material': [], 'Metric': []}"
27a99c21a1324f087b2f144adc119f04137dfd87,"document : Deep Fried Convnets The fully - connected layers of deep convolutional neural networks typically contain over 90 % of the network parameters . Reducing the number of parameters while preserving predictive performance is critically important for training big models in distributed systems and for deployment in embedded devices . In this paper , we introduce a novel Adaptive Fastfood transform to reparameterize the matrix - vector multiplication of fully connected layers . Reparameterizing a fully connected layer with inputs and outputs with the Adaptive Fastfood transform reduces the storage and computational costs costs from to and respectively .",5,"['Task', 'Method', 'Material', 'Metric']","document : Deep Fried Convnets The fully - connected layers of deep convolutional neural networks typically contain over 90 % of the network parameters . Reducing the number of parameters while preserving predictive performance is critically important for training big models in distributed systems and for deployment in embedded devices . In this paper , we introduce a novel Adaptive Fastfood transform to reparameterize the matrix - vector multiplication of fully connected layers . Reparameterizing a fully connected layer with inputs and outputs with the Adaptive Fastfood transform reduces the storage and computational costs costs from to and respectively .","{'Task': ['distributed systems', 'embedded devices'], 'Method': ['Deep Fried Convnets', 'matrix - vector multiplication of fully connected layers', 'big models', 'fully - connected layers of deep convolutional neural networks', 'Adaptive Fastfood transform', 'fully connected layer'], 'Material': [], 'Metric': ['predictive performance', 'storage and computational costs costs']}"
27aa0f3ec934925265f93fac7ff1cd1d70ceb618,"Strong Baselines for Neural Semi - supervised Learning under Domain Shift section : Abstract Novel neural models have been proposed in recent years for learning under domain shift . Most models , however , only evaluate on a single task , on proprietary datasets , or compare to weak baselines , which makes comparison of models difficult . In this paper , we re - evaluate classic general - purpose bootstrapping approaches in the context of neural networks under domain shifts vs. recent neural approaches and propose a novel multi - task tri - training method that reduces the time and space complexity of classic tri - training .",5,"['Task', 'Method', 'Material', 'Metric']","Strong Baselines for Neural Semi - supervised Learning under Domain Shift section : Abstract Novel neural models have been proposed in recent years for learning under domain shift . Most models , however , only evaluate on a single task , on proprietary datasets , or compare to weak baselines , which makes comparison of models difficult . In this paper , we re - evaluate classic general - purpose bootstrapping approaches in the context of neural networks under domain shifts vs. recent neural approaches and propose a novel multi - task tri - training method that reduces the time and space complexity of classic tri - training .","{'Task': ['Neural Semi - supervised Learning', 'learning under domain shift', 'Domain Shift'], 'Method': ['tri - training', 'neural models', 'general - purpose bootstrapping approaches', 'neural networks', 'multi - task tri - training method', 'neural approaches'], 'Material': [], 'Metric': ['time and space complexity']}"
2a86bcdfb1d817ddb76ba202319f8267a36c0f62,"document : PCL : Proposal Cluster Learning for Weakly Supervised Object Detection Weakly Supervised Object Detection ( WSOD ) , using only image - level annotations to train object detectors , is of growing importance in object recognition . In this paper , we propose a novel deep network for WSOD . Unlike previous networks that transfer the object detection problem to an image classification problem using Multiple Instance Learning ( MIL ) , our strategy generates proposal clusters to learn refined instance classifiers by an iterative process . The proposals in the same cluster are spatially adjacent and associated with the same object .",5,"['Task', 'Method', 'Material', 'Metric']","document : PCL : Proposal Cluster Learning for Weakly Supervised Object Detection Weakly Supervised Object Detection ( WSOD ) , using only image - level annotations to train object detectors , is of growing importance in object recognition . In this paper , we propose a novel deep network for WSOD . Unlike previous networks that transfer the object detection problem to an image classification problem using Multiple Instance Learning ( MIL ) , our strategy generates proposal clusters to learn refined instance classifiers by an iterative process . The proposals in the same cluster are spatially adjacent and associated with the same object .","{'Task': ['WSOD )', 'image classification problem', 'Weakly Supervised Object Detection', 'object recognition', 'object detection', 'WSOD'], 'Method': ['Proposal Cluster Learning', 'PCL', 'MIL', 'object detectors', 'instance classifiers', 'proposal clusters', 'iterative process', 'deep network', 'Multiple Instance Learning'], 'Material': [], 'Metric': []}"
2f04ba0f74df046b0080ca78e56898bd4847898b,"document : Aggregate Channel Features for Multi - view Face Detection Face detection has drawn much attention in recent decades since the seminal work by Viola and Jones . While many subsequences have improved the work with more powerful learning algorithms , the feature representation used for face detection still ca n’t meet the demand for effectively and efficiently handling faces with large appearance variance in the wild . To solve this bottleneck , we borrow the concept of channel features to the face detection domain , which extends the image channel to diverse types like gradient magnitude and oriented gradient histograms and therefore encodes rich information in a simple form . We adopt a novel variant called aggregate channel features , make a full exploration of feature design , and discover a multi - scale version of features with better performance .",5,"['Task', 'Method', 'Material', 'Metric']","document : Aggregate Channel Features for Multi - view Face Detection Face detection has drawn much attention in recent decades since the seminal work by Viola and Jones . While many subsequences have improved the work with more powerful learning algorithms , the feature representation used for face detection still ca n’t meet the demand for effectively and efficiently handling faces with large appearance variance in the wild . To solve this bottleneck , we borrow the concept of channel features to the face detection domain , which extends the image channel to diverse types like gradient magnitude and oriented gradient histograms and therefore encodes rich information in a simple form . We adopt a novel variant called aggregate channel features , make a full exploration of feature design , and discover a multi - scale version of features with better performance .","{'Task': ['Multi - view Face Detection', 'detection'], 'Method': ['learning algorithms', 'aggregate channel features', 'feature design', 'feature representation', 'multi - scale version of features', 'Aggregate Channel Features'], 'Material': [], 'Metric': []}"
2f56b1ac5b9faac9527b6814778925e9242cf5fd,"document : Training Region - based Object Detectors with Online Hard Example Mining The field of object detection has made significant advances riding on the wave of region - based ConvNets , but their training procedure still includes many heuristics and hyperparameters that are costly to tune . We present a simple yet surprisingly effective online hard example mining ( OHEM ) algorithm for training region - based ConvNet detectors . Our motivation is the same as it has always been – detection datasets contain an overwhelming number of easy examples and a small number of hard examples .",5,"['Task', 'Method', 'Material', 'Metric']","document : Training Region - based Object Detectors with Online Hard Example Mining The field of object detection has made significant advances riding on the wave of region - based ConvNets , but their training procedure still includes many heuristics and hyperparameters that are costly to tune . We present a simple yet surprisingly effective online hard example mining ( OHEM ) algorithm for training region - based ConvNet detectors . Our motivation is the same as it has always been – detection datasets contain an overwhelming number of easy examples and a small number of hard examples .","{'Task': ['object detection'], 'Method': ['Online Hard Example Mining', 'region - based ConvNet detectors', 'online hard example mining', 'region - based ConvNets', 'Region - based Object Detectors', 'OHEM'], 'Material': [], 'Metric': []}"
2f97ee95cad6a1f13596b108072b846c6f747d4e,"document : The Microsoft 2016 Conversational Speech Recognition System We describe Microsoft ’s conversational speech recognition system , in which we combine recent developments in neural - network - based acoustic and language modeling to advance the state of the art on the Switchboard recognition task . Inspired by machine learning ensemble techniques , the system uses a range of convolutional and recurrent neural networks . I - vector modeling and lattice - free MMI training provide significant gains for all acoustic model architectures . Language model rescoring with multiple forward and backward running RNNLMs , and word posterior - based system combination provide a 20 % boost .",5,"['Task', 'Method', 'Material', 'Metric']","document : The Microsoft 2016 Conversational Speech Recognition System We describe Microsoft ’s conversational speech recognition system , in which we combine recent developments in neural - network - based acoustic and language modeling to advance the state of the art on the Switchboard recognition task . Inspired by machine learning ensemble techniques , the system uses a range of convolutional and recurrent neural networks . I - vector modeling and lattice - free MMI training provide significant gains for all acoustic model architectures . Language model rescoring with multiple forward and backward running RNNLMs , and word posterior - based system combination provide a 20 % boost .","{'Task': [], 'Method': ['machine learning ensemble techniques', 'acoustic model architectures', 'Language model rescoring', 'lattice - free MMI training', 'neural - network - based acoustic and language modeling', 'Conversational Speech Recognition System', 'convolutional and recurrent neural networks', 'forward and backward running RNNLMs', 'I - vector modeling', 'Microsoft ’s conversational speech recognition system', 'word posterior - based system combination'], 'Material': ['Switchboard'], 'Metric': []}"
322a7dad274f440a92548faa8f2b2be666b2d01f,"document : Pyramid Scene Parsing Network Scene parsing is challenging for unrestricted open vocabulary and diverse scenes . In this paper , we exploit the capability of global context information by different - region - based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network ( PSPNet ) . Our global prior representation is effective to produce good quality results on the scene parsing task , while PSPNet provides a superior framework for pixel - level prediction . The proposed approach achieves state - of - the - art performance on various datasets .",5,"['Task', 'Method', 'Material', 'Metric']","document : Pyramid Scene Parsing Network Scene parsing is challenging for unrestricted open vocabulary and diverse scenes . In this paper , we exploit the capability of global context information by different - region - based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network ( PSPNet ) . Our global prior representation is effective to produce good quality results on the scene parsing task , while PSPNet provides a superior framework for pixel - level prediction . The proposed approach achieves state - of - the - art performance on various datasets .","{'Task': ['pixel - level prediction', 'Scene parsing', 'scene parsing task'], 'Method': ['Pyramid Scene Parsing Network', 'global prior representation', 'region - based context aggregation', 'pyramid scene parsing network', 'PSPNet', 'pyramid pooling module'], 'Material': [], 'Metric': []}"
325af39d281d5903a269c01fab8f53d7400a4c49,"document : ArtTrack : Articulated Multi - person Tracking in the Wild In this paper we propose an approach for articulated tracking of multiple people in unconstrained videos . Our starting point is a model that resembles existing architectures for single - frame pose estimation but is substantially faster . We achieve this in two ways : ( 1 ) by simplifying and sparsifying the body - part relationship graph and leveraging recent methods for faster inference , and ( 2 ) by offloading a substantial share of computation onto a feed - forward convolutional architecture that is able to detect and associate body joints of the same person even in clutter . We use this model to generate proposals for body joint locations and formulate articulated tracking as spatio - temporal grouping of such proposals .",5,"['Task', 'Method', 'Material', 'Metric']","document : ArtTrack : Articulated Multi - person Tracking in the Wild In this paper we propose an approach for articulated tracking of multiple people in unconstrained videos . Our starting point is a model that resembles existing architectures for single - frame pose estimation but is substantially faster . We achieve this in two ways : ( 1 ) by simplifying and sparsifying the body - part relationship graph and leveraging recent methods for faster inference , and ( 2 ) by offloading a substantial share of computation onto a feed - forward convolutional architecture that is able to detect and associate body joints of the same person even in clutter . We use this model to generate proposals for body joint locations and formulate articulated tracking as spatio - temporal grouping of such proposals .","{'Task': ['single - frame pose estimation', 'faster inference', 'articulated tracking', 'spatio - temporal grouping', 'articulated tracking of multiple people in unconstrained videos'], 'Method': ['body - part relationship graph', 'ArtTrack', 'feed - forward convolutional architecture', 'Articulated Multi - person Tracking'], 'Material': [], 'Metric': []}"
33261d252218007147a71e40f8367ed152fa2fe0,Question Answering with Subgraph Embeddings section : Abstract . This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few handcrafted features . Our model learns low - dimensional embeddings of words and knowledge base constituents ; these representations are used to score natural language questions against candidate answers .,5,"['Task', 'Method', 'Material', 'Metric']",Question Answering with Subgraph Embeddings section : Abstract . This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few handcrafted features . Our model learns low - dimensional embeddings of words and knowledge base constituents ; these representations are used to score natural language questions against candidate answers .,"{'Task': ['Question Answering'], 'Method': ['Subgraph Embeddings'], 'Material': [], 'Metric': []}"
3448e6a5039417dc1ae890efeca3bef5390ace7c,"document : [ Combinatorial features are essential for the success of many commercial models . Manually crafting these features usually comes with high cost due to the variety , volume and velocity of raw data in web - scale systems . Factorization based models , which measure interactions in terms of vector product , can learn patterns of combinatorial features automatically and generalize to unseen features as well . With the great success of deep neural networks ( DNNs ) in various fields , recently researchers have proposed several DNN - based factorization model to learn both low - and high - order feature interactions .",5,"['Task', 'Method', 'Material', 'Metric']","document : [ Combinatorial features are essential for the success of many commercial models . Manually crafting these features usually comes with high cost due to the variety , volume and velocity of raw data in web - scale systems . Factorization based models , which measure interactions in terms of vector product , can learn patterns of combinatorial features automatically and generalize to unseen features as well . With the great success of deep neural networks ( DNNs ) in various fields , recently researchers have proposed several DNN - based factorization model to learn both low - and high - order feature interactions .","{'Task': ['web - scale systems'], 'Method': ['deep neural networks', 'Factorization based models', 'DNNs', 'DNN'], 'Material': [], 'Metric': ['cost']}"
35734e8724559fb0d494e5cba6a28ad7a3d5dd4d,"document : Explaining and Harnessing Adversarial Examples Several machine learning models , including neural networks , consistently misclassify adversarial examples —inputs formed by applying small but intentionally worst - case perturbations to examples from the dataset , such that the perturbed input results in the model outputting an incorrect answer with high confidence . Early attempts at explaining this phenomenon focused on nonlinearity and overfitting . We argue instead that the primary cause of neural networks ’ vulnerability to adversarial perturbation is their linear nature . This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them : their generalization across architectures and training sets .",5,"['Task', 'Method', 'Material', 'Metric']","document : Explaining and Harnessing Adversarial Examples Several machine learning models , including neural networks , consistently misclassify adversarial examples —inputs formed by applying small but intentionally worst - case perturbations to examples from the dataset , such that the perturbed input results in the model outputting an incorrect answer with high confidence . Early attempts at explaining this phenomenon focused on nonlinearity and overfitting . We argue instead that the primary cause of neural networks ’ vulnerability to adversarial perturbation is their linear nature . This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them : their generalization across architectures and training sets .","{'Task': ['adversarial perturbation'], 'Method': ['neural networks', 'machine learning models', 'architectures'], 'Material': [], 'Metric': []}"
364c1a3df58d87cb40ab33fdf3831cf2862f3570,"document : aNMM : Ranking Short Answer Texts with Attention - Based Neural Matching Model As an alternative to question answering methods based on feature engineering , deep learning approaches such as convolutional neural networks ( CNNs ) and Long Short - Term Memory Models ( LSTMs ) have recently been proposed for semantic matching of questions and answers . To achieve good results , however , these models have been combined with additional features such as word overlap or BM25 scores . Without this combination , these models perform significantly worse than methods based on linguistic feature engineering . In this paper , we propose an attention based neural matching model for ranking short answer text .",5,"['Task', 'Method', 'Material', 'Metric']","document : aNMM : Ranking Short Answer Texts with Attention - Based Neural Matching Model As an alternative to question answering methods based on feature engineering , deep learning approaches such as convolutional neural networks ( CNNs ) and Long Short - Term Memory Models ( LSTMs ) have recently been proposed for semantic matching of questions and answers . To achieve good results , however , these models have been combined with additional features such as word overlap or BM25 scores . Without this combination , these models perform significantly worse than methods based on linguistic feature engineering . In this paper , we propose an attention based neural matching model for ranking short answer text .","{'Task': ['semantic matching of questions and answers', 'Ranking Short Answer Texts', 'ranking short answer text', 'question answering'], 'Method': ['Attention - Based Neural Matching Model', 'attention based neural matching model', 'LSTMs', 'linguistic feature engineering', 'feature engineering', 'convolutional neural networks', 'Long Short - Term Memory Models', 'CNNs', 'aNMM', 'deep learning approaches'], 'Material': [], 'Metric': ['BM25 scores']}"
3842ee1e0fdfeff936b5c49973ff21adfaaf3929,"document : Adversarial Discriminative Domain Adaptation Adversarial learning methods are a promising approach to training robust deep networks , and can generate complex samples across diverse domains . They also can improve recognition despite the presence of domain shift or dataset bias : several adversarial approaches to unsupervised domain adaptation have recently been introduced , which reduce the difference between the training and test domain distributions and thus improve generalization performance . Prior generative approaches show compelling visualizations , but are not optimal on discriminative tasks and can be limited to smaller shifts . Prior discriminative approaches could handle larger domain shifts , but imposed tied weights on the model and did not exploit a GAN - based loss .",5,"['Task', 'Method', 'Material', 'Metric']","document : Adversarial Discriminative Domain Adaptation Adversarial learning methods are a promising approach to training robust deep networks , and can generate complex samples across diverse domains . They also can improve recognition despite the presence of domain shift or dataset bias : several adversarial approaches to unsupervised domain adaptation have recently been introduced , which reduce the difference between the training and test domain distributions and thus improve generalization performance . Prior generative approaches show compelling visualizations , but are not optimal on discriminative tasks and can be limited to smaller shifts . Prior discriminative approaches could handle larger domain shifts , but imposed tied weights on the model and did not exploit a GAN - based loss .","{'Task': ['robust deep networks', 'generalization', 'discriminative tasks', 'unsupervised domain adaptation', 'recognition'], 'Method': ['Adversarial learning methods', 'adversarial approaches', 'Adversarial Discriminative Domain Adaptation', 'GAN', 'generative approaches', 'discriminative approaches'], 'Material': [], 'Metric': []}"
38cc89399dd6f5aaab1654f27ab3c9eeade12a36,"document : Exploiting temporal information for 3D human pose estimation In this work , we address the problem of 3D human pose estimation from a sequence of 2D human poses . Although the recent success of deep networks has led many state - of - the - art methods for 3D pose estimation to train deep networks end - to - end to predict from images directly , the top - performing approaches have shown the effectiveness of dividing the task of 3D pose estimation into two steps : using a state - of - the - art 2D pose estimator to estimate the 2D pose from images and then mapping them into 3D space . They also showed that a low - dimensional representation like 2D locations of a set of joints can be discriminative enough to estimate 3D pose with high accuracy . However , estimation of 3D pose for individual frames leads to temporally incoherent estimates due to independent error in each frame causing jitter .",5,"['Task', 'Method', 'Material', 'Metric']","document : Exploiting temporal information for 3D human pose estimation In this work , we address the problem of 3D human pose estimation from a sequence of 2D human poses . Although the recent success of deep networks has led many state - of - the - art methods for 3D pose estimation to train deep networks end - to - end to predict from images directly , the top - performing approaches have shown the effectiveness of dividing the task of 3D pose estimation into two steps : using a state - of - the - art 2D pose estimator to estimate the 2D pose from images and then mapping them into 3D space . They also showed that a low - dimensional representation like 2D locations of a set of joints can be discriminative enough to estimate 3D pose with high accuracy . However , estimation of 3D pose for individual frames leads to temporally incoherent estimates due to independent error in each frame causing jitter .","{'Task': ['3D human pose estimation', '3D pose'], 'Method': ['low - dimensional representation', 'deep networks', '2D pose estimator'], 'Material': [], 'Metric': ['accuracy', 'error']}"
38e2f851b705faa0d0a698ed9885bd6834440073,"Probabilistic Model - Agnostic Meta - Learning section : Abstract Meta - learning for few - shot learning entails acquiring a prior over previous tasks and experiences , such that new tasks be learned from small amounts of data . However , a critical challenge in few - shot learning is task ambiguity : even when a powerful prior can be meta - learned from a large number of prior tasks , a small dataset for a new task can simply be too ambiguous to acquire a single model ( e.g. , a classifier ) for that task that is accurate . In this paper , we propose a probabilistic meta - learning algorithm that can sample models for a new task from a model distribution .",5,"['Task', 'Method', 'Material', 'Metric']","Probabilistic Model - Agnostic Meta - Learning section : Abstract Meta - learning for few - shot learning entails acquiring a prior over previous tasks and experiences , such that new tasks be learned from small amounts of data . However , a critical challenge in few - shot learning is task ambiguity : even when a powerful prior can be meta - learned from a large number of prior tasks , a small dataset for a new task can simply be too ambiguous to acquire a single model ( e.g. , a classifier ) for that task that is accurate . In this paper , we propose a probabilistic meta - learning algorithm that can sample models for a new task from a model distribution .","{'Task': ['task ambiguity', 'few - shot learning'], 'Method': ['classifier', 'probabilistic meta - learning algorithm', 'Meta - learning', 'Probabilistic Model - Agnostic Meta - Learning'], 'Material': [], 'Metric': []}"
3aa21de1a7c97e0458e10ed5730ce160bb436caa,"document : Pixel2Mesh : Generating 3D Mesh Models from Single RGB Images We propose an end - to - end deep learning architecture that produces a 3D shape in triangular mesh from a single color image . Limited by the nature of deep neural network , previous methods usually represent a 3D shape in volume or point cloud , and it is non - trivial to convert them to the more ready - to - use mesh model . Unlike the existing methods , our network represents 3D mesh in a graph - based convolutional neural network and produces correct geometry by progressively deforming an ellipsoid , leveraging perceptual features extracted from the input image . We adopt a coarse - to - fine strategy to make the whole deformation procedure stable , and define various of mesh related losses to capture properties of different levels to guarantee visually appealing and physically accurate 3D geometry .",5,"['Task', 'Method', 'Material', 'Metric']","document : Pixel2Mesh : Generating 3D Mesh Models from Single RGB Images We propose an end - to - end deep learning architecture that produces a 3D shape in triangular mesh from a single color image . Limited by the nature of deep neural network , previous methods usually represent a 3D shape in volume or point cloud , and it is non - trivial to convert them to the more ready - to - use mesh model . Unlike the existing methods , our network represents 3D mesh in a graph - based convolutional neural network and produces correct geometry by progressively deforming an ellipsoid , leveraging perceptual features extracted from the input image . We adopt a coarse - to - fine strategy to make the whole deformation procedure stable , and define various of mesh related losses to capture properties of different levels to guarantee visually appealing and physically accurate 3D geometry .","{'Task': [], 'Method': ['Pixel2Mesh', '3D Mesh Models', 'coarse - to - fine strategy', 'graph - based convolutional neural network', 'end deep learning architecture', '3D mesh', 'mesh model', 'deep neural network', 'deformation procedure'], 'Material': ['RGB Images'], 'Metric': []}"
3acc07f7f8951617276cf99483ed02aeb0a6eeac,"document : Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes During the last half decade , convolutional neural networks ( CNNs ) have triumphed over semantic segmentation , which is a core task of various emerging industrial applications such as autonomous driving and medical imaging . However , to train CNNs requires a huge amount of data , which is difficult to collect and laborious to annotate . Recent advances in computer graphics make it possible to train CNN models on photo - realistic synthetic data with computer - generated annotations . Despite this , the domain mismatch between the real images and the synthetic data significantly decreases the models ’ performance .",5,"['Task', 'Method', 'Material', 'Metric']","document : Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes During the last half decade , convolutional neural networks ( CNNs ) have triumphed over semantic segmentation , which is a core task of various emerging industrial applications such as autonomous driving and medical imaging . However , to train CNNs requires a huge amount of data , which is difficult to collect and laborious to annotate . Recent advances in computer graphics make it possible to train CNN models on photo - realistic synthetic data with computer - generated annotations . Despite this , the domain mismatch between the real images and the synthetic data significantly decreases the models ’ performance .","{'Task': ['semantic segmentation', 'autonomous driving', 'medical imaging', 'computer graphics', 'industrial applications', 'Semantic Segmentation of Urban Scenes'], 'Method': ['CNN', 'convolutional neural networks', 'CNNs', 'Curriculum Domain Adaptation'], 'Material': [], 'Metric': []}"
3ca3993b1f3536b15112f759067f62e999c5d38f,"BB8 : A Scalable , Accurate , Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth section : Abstract We introduce a novel method for 3D object detection and pose estimation from color images only . We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background .",5,"['Task', 'Method', 'Material', 'Metric']","BB8 : A Scalable , Accurate , Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth section : Abstract We introduce a novel method for 3D object detection and pose estimation from color images only . We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background .","{'Task': ['3D object detection', 'objects of interest in 2D even', 'Predicting the 3D Poses of Challenging Objects', 'pose estimation'], 'Method': ['segmentation', 'Partial Occlusion Method', 'BB8'], 'Material': [], 'Metric': []}"
3cf31ecb2724b5088783d7c96a5fc0d5604cbf41,"document : Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations We present a simple and effective scheme for dependency parsing which is based on bidirectional - LSTMs ( BiLSTMs ) . Each sentence token is associated with a BiLSTM vector representing the token in its sentential context , and feature vectors are constructed by concatenating a few BiLSTM vectors . The BiLSTM is trained jointly with the parser objective , resulting in very effective feature extractors for parsing . We demonstrate the effectiveness of the approach by applying it to a greedy transition - based parser as well as to a globally optimized graph - based parser .",5,"['Task', 'Method', 'Material', 'Metric']","document : Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations We present a simple and effective scheme for dependency parsing which is based on bidirectional - LSTMs ( BiLSTMs ) . Each sentence token is associated with a BiLSTM vector representing the token in its sentential context , and feature vectors are constructed by concatenating a few BiLSTM vectors . The BiLSTM is trained jointly with the parser objective , resulting in very effective feature extractors for parsing . We demonstrate the effectiveness of the approach by applying it to a greedy transition - based parser as well as to a globally optimized graph - based parser .","{'Task': ['Dependency Parsing', 'dependency parsing', 'parsing'], 'Method': ['BiLSTMs', 'greedy transition - based parser', 'feature extractors', 'Bidirectional LSTM Feature Representations', 'BiLSTM', 'bidirectional - LSTMs', 'globally optimized graph - based parser'], 'Material': [], 'Metric': ['parser objective']}"
3daa086acd367dc971a2dc1382caba2031294233,"Holistic , Instance - level Human Parsing section : Abstract Object parsing - the task of decomposing an object into its semantic parts - has traditionally been formulated as a category - level segmentation problem . Consequently , when there are multiple objects in an image , current methods can not count the number of objects in the scene , nor can they determine which part belongs to which object . We address this problem by segmenting the parts of objects at an instance - level , such that each pixel in the image is assigned a part label , as well as the identity of the object it belongs to .",5,"['Task', 'Method', 'Material', 'Metric']","Holistic , Instance - level Human Parsing section : Abstract Object parsing - the task of decomposing an object into its semantic parts - has traditionally been formulated as a category - level segmentation problem . Consequently , when there are multiple objects in an image , current methods can not count the number of objects in the scene , nor can they determine which part belongs to which object . We address this problem by segmenting the parts of objects at an instance - level , such that each pixel in the image is assigned a part label , as well as the identity of the object it belongs to .","{'Task': ['category - level segmentation problem', 'Holistic , Instance - level Human Parsing', 'decomposing an object', 'Object parsing'], 'Method': [], 'Material': [], 'Metric': []}"
408e8eecc14c5cc60bbdfc486ba7a7fc97031788,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks Current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training . In this paper we present an approach for training a convolutional neural network using only unlabeled data . We train the network to discriminate between a set of surrogate classes . Each surrogate class is formed by applying a variety of transformations to a randomly sampled ’ seed ’ image patch . We find that this simple feature learning algorithm is surprisingly successful when applied to visual object recognition .,5,"['Task', 'Method', 'Material', 'Metric']",Discriminative Unsupervised Feature Learning with Convolutional Neural Networks Current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training . In this paper we present an approach for training a convolutional neural network using only unlabeled data . We train the network to discriminate between a set of surrogate classes . Each surrogate class is formed by applying a variety of transformations to a randomly sampled ’ seed ’ image patch . We find that this simple feature learning algorithm is surprisingly successful when applied to visual object recognition .,"{'Task': ['visual object recognition', 'supervised training'], 'Method': ['network', 'convolutional neural networks', 'feature learning algorithm', 'Discriminative Unsupervised Feature Learning with Convolutional Neural Networks'], 'Material': [], 'Metric': []}"
4365eb43a635bc6431dfaf3af1f7bf7bf55522cc,"document : CoupleNet : Coupling Global Structure with Local Parts for Object Detection The region - based Convolutional Neural Network ( CNN ) detectors such as Faster R - CNN or R - FCN have already shown promising results for object detection by combining the region proposal subnetwork and the classification subnetwork together . Although R - FCN has achieved higher detection speed while keeping the detection performance , the global structure information is ignored by the position - sensitive score maps . To fully explore the local and global properties , in this paper , we propose a novel fully convolutional network , named as CoupleNet , to couple the global structure with local parts for object detection . Specifically , the object proposals obtained by the Region Proposal Network ( RPN ) are fed into the the coupling module which consists of two branches .",5,"['Task', 'Method', 'Material', 'Metric']","document : CoupleNet : Coupling Global Structure with Local Parts for Object Detection The region - based Convolutional Neural Network ( CNN ) detectors such as Faster R - CNN or R - FCN have already shown promising results for object detection by combining the region proposal subnetwork and the classification subnetwork together . Although R - FCN has achieved higher detection speed while keeping the detection performance , the global structure information is ignored by the position - sensitive score maps . To fully explore the local and global properties , in this paper , we propose a novel fully convolutional network , named as CoupleNet , to couple the global structure with local parts for object detection . Specifically , the object proposals obtained by the Region Proposal Network ( RPN ) are fed into the the coupling module which consists of two branches .","{'Task': ['Object Detection', 'detection', 'object detection'], 'Method': ['region proposal subnetwork', 'fully convolutional network', 'RPN', 'CNN', 'CoupleNet', 'coupling module', 'Region Proposal Network', 'classification subnetwork', 'R - FCN', 'Convolutional Neural Network'], 'Material': [], 'Metric': ['detection speed']}"
436b07bebaa1d1f05ef85415e10374048d25334d,"OUTRAGEOUSLY LARGE NEURAL NETWORKS : THE SPARSELY - GATED MIXTURE - OF - EXPERTS LAYER section : ABSTRACT The capacity of a neural network to absorb information is limited by its number of parameters . Conditional computation , where parts of the network are active on a per - example basis , has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation .",5,"['Task', 'Method', 'Material', 'Metric']","OUTRAGEOUSLY LARGE NEURAL NETWORKS : THE SPARSELY - GATED MIXTURE - OF - EXPERTS LAYER section : ABSTRACT The capacity of a neural network to absorb information is limited by its number of parameters . Conditional computation , where parts of the network are active on a per - example basis , has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation .","{'Task': ['Conditional computation', 'computation', 'model capacity'], 'Method': ['OUTRAGEOUSLY LARGE NEURAL NETWORKS', 'SPARSELY - GATED MIXTURE - OF - EXPERTS LAYER', 'neural network'], 'Material': [], 'Metric': []}"
44078d0daed8b13114cffb15b368acc467f96351,"document : Triplet Probabilistic Embedding for Face Verification and Clustering Despite significant progress made over the past twenty five years , unconstrained face verification remains a challenging problem . This paper proposes an approach that couples a deep CNN - based approach with a low - dimensional discriminative embedding step , learned using triplet probability constraints to address the unconstrained face verification problem . Aside from yielding performance improvements , this embedding provides significant advantages in terms of memory and for post - processing operations like subject specific clustering . Experiments on the challenging IJB - A dataset show that the proposed algorithm performs close to the state of the art methods in verification and identification metrics , while requiring much less training data and training / test time .",5,"['Task', 'Method', 'Material', 'Metric']","document : Triplet Probabilistic Embedding for Face Verification and Clustering Despite significant progress made over the past twenty five years , unconstrained face verification remains a challenging problem . This paper proposes an approach that couples a deep CNN - based approach with a low - dimensional discriminative embedding step , learned using triplet probability constraints to address the unconstrained face verification problem . Aside from yielding performance improvements , this embedding provides significant advantages in terms of memory and for post - processing operations like subject specific clustering . Experiments on the challenging IJB - A dataset show that the proposed algorithm performs close to the state of the art methods in verification and identification metrics , while requiring much less training data and training / test time .","{'Task': ['post - processing operations', 'unconstrained face verification problem', 'Clustering', 'Face Verification', 'unconstrained face verification'], 'Method': ['Triplet Probabilistic Embedding', 'CNN', 'subject specific clustering', 'low - dimensional discriminative embedding step'], 'Material': ['IJB - A dataset'], 'Metric': ['verification and identification metrics', 'training / test time', 'memory']}"
45429c281e30f9e87ebcd1ae42e0656d2ead24d1,"document : High - Resolution Image Synthesis and Semantic Manipulation with Conditional GANs We present a new method for synthesizing high - resolution photo - realistic images from semantic label maps using conditional generative adversarial networks ( conditional GANs ) . Conditional GANs have enabled a variety of applications , but the results are often limited to low - resolution and still far from realistic . In this work , we generate visually appealing results with a novel adversarial loss , as well as new multi - scale generator and discriminator architectures . Furthermore , we extend our framework to interactive visual manipulation with two additional features .",5,"['Task', 'Method', 'Material', 'Metric']","document : High - Resolution Image Synthesis and Semantic Manipulation with Conditional GANs We present a new method for synthesizing high - resolution photo - realistic images from semantic label maps using conditional generative adversarial networks ( conditional GANs ) . Conditional GANs have enabled a variety of applications , but the results are often limited to low - resolution and still far from realistic . In this work , we generate visually appealing results with a novel adversarial loss , as well as new multi - scale generator and discriminator architectures . Furthermore , we extend our framework to interactive visual manipulation with two additional features .","{'Task': ['High - Resolution Image Synthesis', 'semantic label maps', 'Semantic Manipulation', 'synthesizing high - resolution photo - realistic images', 'interactive visual manipulation'], 'Method': ['multi - scale generator and discriminator architectures', 'conditional GANs', 'adversarial loss', 'Conditional GANs', 'conditional generative adversarial networks'], 'Material': [], 'Metric': []}"
455da02e5048dffb51fb6ab5eb8aeca5926c9d9a,"document : Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition Existing deep convolutional neural networks ( CNNs ) require a fixed - size ( , 224 224 ) input image . This requirement is “ artificial ” and may reduce the recognition accuracy for the images or sub - images of an arbitrary size / scale . In this work , we equip the networks with another pooling strategy , “ spatial pyramid pooling ” , to eliminate the above requirement .",5,"['Task', 'Method', 'Material', 'Metric']","document : Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition Existing deep convolutional neural networks ( CNNs ) require a fixed - size ( , 224 224 ) input image . This requirement is “ artificial ” and may reduce the recognition accuracy for the images or sub - images of an arbitrary size / scale . In this work , we equip the networks with another pooling strategy , “ spatial pyramid pooling ” , to eliminate the above requirement .","{'Task': ['Visual Recognition'], 'Method': ['Spatial Pyramid Pooling', 'Deep Convolutional Networks', 'pooling strategy', 'CNNs', 'deep convolutional neural networks', 'spatial pyramid pooling'], 'Material': [], 'Metric': ['recognition accuracy']}"
